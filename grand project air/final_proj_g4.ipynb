{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submitted by: Group G4**->(Raja Ram Chaudhary,Umesha B K,Gowthami R)<br>\n",
    "**2020-07-04**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](airindia_new.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Business Understanding](#1)<br>\n",
    "2. [Analytic Approach](#2)<br>  \n",
    "3. [Exploratory Data Analysis (EDA)](#3)<br>\n",
    "4. [Descriptive Statistical Analysis](#4)<br>\n",
    "5. [Data Preparation](#5)<br>\n",
    "6. [Correlation heatmap of dataset](#6)<br>\n",
    "7. [Train the Model](#7)<br> \n",
    "8. [Saving the Model](#8)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used Data Scientist Tools:\n",
    "<ul>\n",
    "    <li>Jupyter Notebook-6.0.3 </li>\n",
    "    <li>Python-3.6.10 </li>\n",
    "    <li>iPython-7.13.0 </li>\n",
    "    <li>Numpy-1.18.4 </li>\n",
    "    <li>Pandas-1.0.3 </li>\n",
    "    <li>Matplotlib-3.2.1 </li>\n",
    "    <li>Seaborn-0.10.1 </li>\n",
    "    <li>Scipy-1.4.1 </li>\n",
    "    <li>Scikit-learn-0.22 </li>   \n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem is the Linear Models and Time Series Forecasting(We solve by Linear Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding  <a id=\"1\"></a>\n",
    "This is the **Data Science Methodology**, a flowchart that begins with business understanding.<br>\n",
    "Q: What is the problem that we are tried to solve?    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Air travel is the safest mode of transport in any times. Passengers are therefore likely to switch in large numbers away from rail and car to air travel. India’s commercial aircraft are around 670 & skies are empty now.India’s aviation system is going to boom because of oil prices are decreased. In this time, Passengers want to fly in cheaper rate but companies want to generate valuable revenue at same time. Due to this, there has fluctuations in price of Air (AirFare) over time to get seat. This is the problem to solve by building a predictive model by exploring previous airfare data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business objective-** To predict airfare, as domestic air travel is popular these days in India with different air ticket booking channels, travelers are trying to make sense and understand how airlines price their tickets over time. \n",
    "We want you to explore previous airfare data and build a model to predict the price fluctuations over time so that the consumer could benefit from it. We want you to identify dependency over many endogenous variables. You are free to look at different models from the space of forecasting and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytic Approach<a id=\"2\"></a>\n",
    "<li> How can we used data to answer the question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have acquired the data, we have done the followings:\n",
    "\n",
    "Diagnosed data quality:\n",
    "<li>If there has a problem with data quality.</li>\n",
    "<li>The data has corrected.</li>\n",
    "<li>Explored data to understand the data and find scenarios for performing the analysis.</li>\n",
    "<li>Identify dependency over many endogenous variables.</li>\n",
    "<li>Compared different models to evaluate best model.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Import necessaries library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read given data by help of pandas function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-68a45f335d41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\Vinayaka\\\\Desktop\\\\grand project air\\\\air_fair.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\Vinayaka\\\\Desktop\\\\grand project air\\\\air_fair.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)<a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show top 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InvoiceDate converted into datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['InvoiceDate']=pd.to_datetime(data['InvoiceDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of Date, Year, Month, Day, Hour & Minute from InvoiceDate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date']=data['InvoiceDate'].dt.date\n",
    "data['Year']=data['InvoiceDate'].dt.year\n",
    "data['Month']=data['InvoiceDate'].dt.month\n",
    "data['Day']=data['InvoiceDate'].dt.day\n",
    "data['Hour']=data['InvoiceDate'].dt.hour\n",
    "data['Minute']=data['InvoiceDate'].dt.minute\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop InvoiceDate column after extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"InvoiceDate\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearrange of columns as our choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Date','Year', 'Month','Day','Hour','Minute','ProductType','ItineraryType','NetFare']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show total counts of records in different Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Above stat shows that Year 2019 has much transactions & good bussiness in compare with 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show total counts of records in different Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Month.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑Above stat shows that Month \"May\" passengers travelled much. August Month was not perfect month for travelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show total counts of records in different dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Date.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Above counts shows that the NetFare records at date of 2019-06-05 is maximum and minimum at 2018-07-31. Google shows that maximum transaction recods due to celebration day declared by UN , World Environment Day & minimum due to leap month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show total counts of records in different hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Hour.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Above counts shows that NetFare records at the time (hour of time) 17.0(5:00 PM) is maximum and minimum at 4.0(4:00 AM) morning. It means people buy or book theirs ticket after office time and minimum at 4:00 oclock morning at end of sleep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show total counts of records in different Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Minute.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Above counts shows that NetFare records booked or baught at 1 minute later than integer hour. Working of booking starts at certain integer hour and finish within in minute. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse strings to datetime type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data.Date, infer_datetime_format=True)\n",
    "df=data.set_index(['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data index sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Date').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,3))\n",
    "df.groupby('Year')['NetFare'].mean().plot.bar()  \n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('NetFare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ It is obvious that NetFare was high in 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,3))\n",
    "df.groupby(['Year','Month'])['NetFare'].mean().plot.bar()  \n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('NetFare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ It is obvious that NetFare was high in Year 2018 with Month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,3))\n",
    "df.groupby('Hour')['NetFare'].mean().plot.bar()  \n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('NetFare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Peak of bar at 19:00 PM is high and lowest at 5:00 AM. See, NetFare at above time are 4800 & 3000 Rupees respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "df.groupby('Minute')['NetFare'].mean().plot.bar()  \n",
    "plt.xlabel('Minute')\n",
    "plt.ylabel('NetFare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ NetFare at 6,19,31,46 minutes are high & at 13,25,37,49 minutes are low. See, low NetFare are nearly 3000 rupees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistical Analysis <a id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the general info about dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ DatetimeIndex: 278466 entries, 2018-01-12 to 2019-10-06. See Dtype also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show unique value of ProductType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ProductType.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show unique value of Itinerary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ItineraryType.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the statistical calculations of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Concentrate on NetFare Columns. We already seen many plots have average netfare 3000-5000. But see value now,-497324 & 497678. These are 100% outliers. So, suggest go through clean Data Preparaion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation <a id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Evaluating for Missing Data</h4>\n",
    "There are two methods to detect missing data:\n",
    "<ol>\n",
    " <li><b>.isnull()</b></li>\n",
    " <li><b>.notnull()</b></li>\n",
    "</ol>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find missing value by Boolean method:\n",
    "**\"True\"** stands for missing value, while **\"False\"** stands for not missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value = df.isnull()\n",
    "missing_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count missing values in each column\n",
    "\n",
    "Using a for loop in Python, we can quickly figure out the number of missing values in each column.<br>\n",
    "**\"True\" stands for missing value, while \"False\" stands for not missing value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in missing_value.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_value[column].value_counts())\n",
    "    print(\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the summary above, each column has 278466 rows of data, all columns containing missing data:\n",
    "<ol>\n",
    "<li>\"Year\",\"Month\",\"Day\",\"Hour\",\"Minute\": 2 missing data</li>\n",
    "<li>\"ProductType\": 2 missing data</li>\n",
    "<li>\"ItineraryType\": 32777 missing data</li>    \n",
    "<li>\"NetFare\": 60890 missing data</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deal with missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Drop rows:</b>\n",
    "<ol>\n",
    "    <li>\"Year\",\"Month\",\"Day\",\"Hour\",\"Minute\": 2 missing data, drop them , two observations among large dataset are not so big deals</li>\n",
    "    <li>\"ProductType\": 2 missing data, drop them , two observations among large dataset are not so big deals</li>\n",
    "    <li>\"ItineraryType\": 32777 missing data, drop them , they are totally empty, we have huge data</li>\n",
    "    <li>\"NetFare\": 60890 missing data, drop whole rows, they are totally empty</li>  \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop missing values **[\"Year\",\"Month\",\"Day\",\"Hour\",\"Minute\"]** in observations, the two rows are negelegible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"Year\",\"Month\",\"Day\",\"Hour\",\"Minute\"], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop missing values **[ProductType]** in observations, the two rows are negelegible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"ProductType\"], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop missing values **[ItineraryType]** in observations, they are not very sensitive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"ItineraryType\"], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop missing values **[NetFare]** in observations, they are completly empty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"NetFare\"], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset index, because we droped many rows & sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().sort_values(by='Date').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Clean** data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"True\" stands for missing value, while \"False\" stands for not missing value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_clean.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (df_clean[column].value_counts())\n",
    "    print(\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAW Data observations=**278466**, CLEANED Data observations=**184800**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Box Plot** to find out the outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1=plt.subplots()\n",
    "fig.set_size_inches(5,15)\n",
    "plt.boxplot(df[\"NetFare\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Box-plot shows much outliers both sides, it has to remove, actually outliers makes execution lazy and make noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='NetFare', by='ProductType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='NetFare', by='ItineraryType')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Compared with International NetFare, Domestic airfare has less outliers, advised to remove outliers in both variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='NetFare', by='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='NetFare', by='Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='NetFare', by='Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='NetFare', by='Hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='NetFare', by='Minute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Above all box-plots show that there has much outliers in every columns. So, there has necessary to remove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram plot of NetFare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NetFare.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ By graph can be analysed that negative values are also existed. Nearly 25000 transactions are with negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ItineraryType.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Counts of Domestic AirFare consists of huge amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ProductType.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ By graph can be conclude that Sub-type Air of ProductType plays main role in a group. It means correlation with NetFare should be strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Hour.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Plot shows that 14:00 PM-16:00 PM, after lunch time, people book or buy NetFare services. Minimest interaction at (2:00 AM-4:00 AM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Minute.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Plot shows that nobody booked or baught NetFare Services at 59:00 minute. Clear insight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying Outliers with Interquartile Range (IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1  \n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below generates an output with the 'True' and 'False' values. Points where the values are 'True' represent the presence of the outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df  < (Q1 - 1.5 * IQR)) | (df  > (Q3 + 1.5 * IQR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying skewness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['NetFare'].skew())\n",
    "df['NetFare'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Data is highly right skewed (11.13). Max value is 497678.It is due to outliers. So, there has necessary to delete outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the **IQR method** to delete outliers from records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(df_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.reset_index().sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among CLEAN Data observations=**184800**, after delation of outlier REMAINDER Data observations=**167132** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-Check outliers by Box-Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1=plt.subplots()\n",
    "fig.set_size_inches(5,5)\n",
    "plt.boxplot(df_out[\"NetFare\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1=plt.subplots()\n",
    "fig.set_size_inches(5,5)\n",
    "plt.boxplot(df_out[\"Minute\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ **Oah..**, we got box plot with free outliers. Its great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_out['NetFare'].skew())\n",
    "df_out['NetFare'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ See the Skewness=0.10, nearly 0. Data became normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Good!</b> Now, we obtain the dataset with no missing values, no outliers , no dispersion & sort indexed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bar plot for ProductType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['ProductType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ ProductType Air and Hotel are distinct clear and maximum. Maximum has Air services and maximum has booked Hotel too or included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['ProductType'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Other Product type is also high, but not clear what it is. Air & Hotel are distinct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bar plot of ItineraryType ( Domestic, International)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['ItineraryType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['ItineraryType'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Travellers are not flying abroad much. It means peoples are flying inside country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning\n",
    "Binning is a process of transforming continuous numerical variables into discrete categorical 'bins', for grouped analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of NetFare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_out[\"NetFare\"])\n",
    "plt.xlabel(\"NetFare\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"NetFare-Counts Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Above plot shows that NetFare between 2500-4000 has nearly 50000.It means fifty thousands travellers baught ticket between 2500-4000 rupees or units of prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dummie variables of ['ProductType', 'ItineraryType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df=pd.get_dummies(df_out, columns=['ProductType', 'ItineraryType'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df.rename(columns = {'ProductType_Air Cancellation':'ProTypeAirCanc','ProductType_Air Debit Note':'ProTypeAirDebtNote','ProductType_Air Loss':'ProTypeAirLoss','ProductType_Hotel':'ProTypeHot','ProductType_Hotel Cancellation':'ProTypeHotCanc','ProductType_Hotel Debit Note':'ProTypeHotDebNote','ProductType_Hotel Loss':'ProTypeHotLoss','ProductType_Other Product':'ProTypeOthPro','ProductType_Other Product Cancellation':'ProTypeOthProCanc','ProductType_Other Product Debit Note':'ProTypeOthProDebNote','ItineraryType_International':'IteTypeInter'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ProductTypeAir~NetFare Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"ProTypeAirCanc\", y=\"NetFare\", data=dummy_df, x_estimator=np.mean);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ As Product Type Air increases NetFare also increases. As full paid of Air becomes NetFare=5000IRS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ProductTypeHotel~NetFare Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"ProTypeHot\", y=\"NetFare\", data=dummy_df, x_estimator=np.mean);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Shaded blue light portion is 95% confidence interval. As Product Type Hotel increases NetFare also increases.As full paid of Hotel becomes=5500IRS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IteneraryTypeInternational~NetFare Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"IteTypeInter\", y=\"NetFare\", data=dummy_df, x_estimator=np.mean);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ As reverse to Domestic, as Itenerary Type International increases NetFare also increases. 95% confidence NetFare range=3800-4350."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting dtypes using astype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df[\"Year\"]= dummy_df[\"Year\"].astype(int) \n",
    "dummy_df[\"Month\"]= dummy_df[\"Month\"].astype(int) \n",
    "dummy_df[\"Day\"]= dummy_df[\"Day\"].astype(int) \n",
    "dummy_df[\"Hour\"]= dummy_df[\"Hour\"].astype(int) \n",
    "dummy_df[\"Minute\"]= dummy_df[\"Minute\"].astype(int) \n",
    "dummy_df[\"ProTypeAirCanc\"]= dummy_df[\"ProTypeAirCanc\"].astype(int) \n",
    "dummy_df[\"ProTypeAirDebtNote\"]= dummy_df[\"ProTypeAirDebtNote\"].astype(int) \n",
    "dummy_df[\"ProTypeAirLoss\"]= dummy_df[\"ProTypeAirLoss\"].astype(int) \n",
    "dummy_df[\"ProTypeHot\"]= dummy_df[\"ProTypeHot\"].astype(int) \n",
    "dummy_df[\"ProTypeHotCanc\"]= dummy_df[\"ProTypeHotCanc\"].astype(int) \n",
    "dummy_df[\"ProTypeHotDebNote\"]= dummy_df[\"ProTypeHotDebNote\"].astype(int) \n",
    "dummy_df[\"ProTypeHotLoss\"]= dummy_df[\"ProTypeHotLoss\"].astype(int) \n",
    "dummy_df[\"ProTypeOthPro\"]= dummy_df[\"ProTypeOthPro\"].astype(int)\n",
    "dummy_df[\"ProTypeOthProCanc\"]= dummy_df[\"ProTypeOthProCanc\"].astype(int) \n",
    "dummy_df[\"ProTypeAirLoss\"]= dummy_df[\"ProTypeAirLoss\"].astype(int) \n",
    "dummy_df[\"ProTypeOthProDebNote\"]= dummy_df[\"ProTypeOthProDebNote\"].astype(int) \n",
    "dummy_df[\"IteTypeInter\"]= dummy_df[\"IteTypeInter\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df=dummy_df[['IteTypeInter','Year', 'Month', 'Day', 'Hour', 'Minute','ProTypeHot','ProTypeOthPro', 'ProTypeAirCanc','ProTypeHotCanc','ProTypeAirLoss','ProTypeHotLoss','NetFare']]\n",
    "dummy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation heatmap of dataset<a id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_heatmap(dummy_df):\n",
    "    hmap , ax = plt.subplots(figsize =(14, 12))\n",
    "    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "    \n",
    "    hmap= sns.heatmap(\n",
    "        dummy_df.corr(), \n",
    "        cmap = \"YlGn\",\n",
    "        square=True, \n",
    "        cbar_kws={'shrink':.9 }, \n",
    "        ax=ax,\n",
    "        annot=True, \n",
    "        linewidths=0.1,vmax=1.0, linecolor='white',\n",
    "        annot_kws={'fontsize':12 }\n",
    "    )\n",
    "    \n",
    "    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "\n",
    "correlation_heatmap(dummy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Please go on NetFare columns. Pearson Correlation of Features (Month,Day,Hour,Minute, ProductType_Hotel,  & ItineraryType_International) shows that they are highly corelated i.e. positive values. Others variables less effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting features & target of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dummy_df.drop(['NetFare'], axis=1)\n",
    "y = dummy_df.NetFare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit or Train the Model<a id=\"7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train accuracy: {}'.format(lr_model.score(X_train, y_train)))\n",
    "print('Test accuracy: {}'.format(lr_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "d = y_test - y_pred\n",
    "mse_f = np.mean(d**2)\n",
    "mae_f = np.mean(abs(d))\n",
    "rmse_f = np.sqrt(mse_f)\n",
    "r2_f = 1-(sum(d**2)/sum((y-np.mean(y))**2))\n",
    "\n",
    "print(\"Results by manual calculation:\")\n",
    "print(\"MAE:\",mae_f)\n",
    "print(\"MSE:\", mse_f)\n",
    "print(\"RMSE:\", rmse_f)\n",
    "print(\"R-Squared:\", r2_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle model<a id=\"8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(lr_model,'4july_lr_model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
